{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chicken-evolution",
   "metadata": {},
   "source": [
    "# Lab Week 6\n",
    "One issue in natural language processing is the identification of sentiment of texts, are they positive, negative or neutral to some concept. This dataset (https://github.com/thanhtut/info284_lab/blob/master/assignment1/twitter-airline-sentiment/Tweets.csv) has a collection of tweets about airlines with corresponding sentiments (negative, positive, neutral).\n",
    "\n",
    "The task :\n",
    "The task we want you to do is to run three machine learning models using Naïve Bayes on the tweet texts.\n",
    "\n",
    "1. Prepare the data for machine learning. Extract the relevant columns, do language preprocessing of the tweets, etc.\n",
    "2. Run a BernoulliNB to classify sentiment\n",
    "3. Run a MultiomialNB to classify sentiment\n",
    "4. Run a MultinomialNB to classify sentiment, but insteadof using a count vector you should use a TF-IDF-vector for each instance. What is TF-IDF? Read sources on information retrieval, and also look here: https://stackabuse.com/text-classification-with-python-and-scikit-learn\n",
    "\n",
    "How does these three approaches compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-flood",
   "metadata": {},
   "source": [
    "### What can we tell about the data?\n",
    "The dtypes vary, none of the data has nulls, we´ll double check anyways, mostly objects witch will be timeforamts and strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-cholesterol",
   "metadata": {},
   "source": [
    "We can analyse the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wanted-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spectacular-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe is (14640, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataframe is\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conservative-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "endless-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage null or na values in tweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id                         0.00\n",
       "airline_sentiment                0.00\n",
       "airline_sentiment_confidence     0.00\n",
       "negativereason                  37.31\n",
       "negativereason_confidence       28.13\n",
       "airline                          0.00\n",
       "airline_sentiment_gold          99.73\n",
       "name                             0.00\n",
       "negativereason_gold             99.78\n",
       "retweet_count                    0.00\n",
       "text                             0.00\n",
       "tweet_coord                     93.04\n",
       "tweet_created                    0.00\n",
       "tweet_location                  32.33\n",
       "user_timezone                   32.92\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Percentage null or na values in tweets\")\n",
    "((df.isnull() | df.isna()).sum() * 100 / df.index.size).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "original-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "14640\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().any())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decent-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14604\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-progressive",
   "metadata": {},
   "source": [
    "### Choosing the necesarry columns:\n",
    "After removing duplications and looking for emtpy columns we can pick out the colums that should be used.\n",
    "`airline_sentiment_gold` , `negativereason_gold` and `tweet_coord` is all but empty so they will prove no help.\n",
    "`tweet_id`, `name` and `tweet_created` are rather unique so they will not give anything to the table. The confidence columns are also uneccesary. That leaves us with the remaining:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "applied-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.drop(columns = [\n",
    "    \"airline_sentiment\", \"airline_sentiment_confidence\", \"negativereason_confidence\",\n",
    "    \"tweet_id\", \"airline_sentiment_gold\", \"name\", \"negativereason_gold\",\n",
    "    \"tweet_coord\", \"tweet_created\", \"tweet_location\", \"user_timezone\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interior-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14604 entries, 0 to 14639\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   negativereason  9159 non-null   object\n",
      " 1   airline         14604 non-null  object\n",
      " 2   retweet_count   14604 non-null  int64 \n",
      " 3   text            14604 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 570.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "operational-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets[\"text\"]\n",
    "y = df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mathematical-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14604,)\n",
      "(14604,)\n",
      "-------------\n",
      "(14604,)\n",
      "(14604,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "#y = y.to_numpy()\n",
    "#y = y.reshape(y.shape[0],1)\n",
    "print(\"-------------\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-newcastle",
   "metadata": {},
   "source": [
    "Lets Vectorize the data using `CountVectorizer` the sklearn function converts a collection of text documents to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "turned-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "X = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-parameter",
   "metadata": {},
   "source": [
    "Lets split the data into random train and test subsets and fit it to the `BernoulliNB()` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "manufactured-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "latest-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB().fit(X_train, y_train)\n",
    "p_train = model.predict(X_train)\n",
    "p_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-blackberry",
   "metadata": {},
   "source": [
    "Now let us calculate the accurasy and look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "modular-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.831826896740619\n",
      " Test Accuracy: 0.7619830183511367\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_train, p_train)\n",
    "acc_test = accuracy_score(y_test, p_test)\n",
    "print(f\"Train Accuracy: {acc_train}\\n Test Accuracy: {acc_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
